:import "Spec"

:class ByteStreamChunkedReaderSpec
  :is Spec
  :const describes: "ByteStream.ChunkedReader"

  :it "can accept chunks, advance, and read tokens"
    stream = ByteStream.ChunkedReader.new
    assert: stream.bytes_ahead == 0
    assert: stream.bytes_ahead_of_marker == 0
    assert: stream.token_byte_size == 0
    assert: stream.token_as_string == ""

    // Add a chunk so that those bytes are available for reading.
    stream << b"hello"
    assert: stream.bytes_ahead == 5
    assert: stream.bytes_ahead_of_marker == 5
    assert: stream.token_byte_size == 0
    assert: stream.token_as_string == ""

    // Advance the cursor partway through the stream, leaving a token marked.
    assert no_error: stream.advance!(4)
    assert: stream.bytes_ahead == 1
    assert: stream.bytes_ahead_of_marker == 5
    assert: stream.token_byte_size == 4
    assert: stream.token_as_string == "hell"

    // Try to advance further and fail partway through,
    // leaving the cursor pointing to the end of the stream.
    assert error: stream.advance!(4)
    assert: stream.bytes_ahead == 0
    assert: stream.bytes_ahead_of_marker == 5
    assert: stream.token_byte_size == 5
    assert: stream.token_as_string == "hello"

    // Rewind the cursor back to the marker position at the start of the stream.
    stream.rewind_to_marker
    assert: stream.bytes_ahead == 5
    assert: stream.bytes_ahead_of_marker == 5
    assert: stream.token_byte_size == 0
    assert: stream.token_as_string == ""

    // Add some more chunks.
    stream << b"world"
    stream << b"lings"
    assert: stream.bytes_ahead == 15
    assert: stream.bytes_ahead_of_marker == 15
    assert: stream.token_byte_size == 0
    assert: stream.token_as_string == ""

    // Advance the cursor and then move the marker forward by 3 bytes.
    assert no_error: stream.advance!(3)
    stream.mark_here
    assert: stream.bytes_ahead == 12
    assert: stream.bytes_ahead_of_marker == 12
    assert: stream.token_byte_size == 0
    assert: stream.token_as_string == ""

    // Advance the cursor by one byte then peek ahead of the cursor position.
    assert no_error: stream.advance!(1)
    assert: stream.peek_byte! == 'o'
    assert: stream.peek_byte!(1) == 'w'
    assert: stream.peek_byte!(2) == 'o'
    assert: stream.peek_byte!(3) == 'r'
    assert: stream.peek_byte!(4) == 'l'
    assert: stream.peek_byte!(5) == 'd'
    assert: stream.peek_byte!(6) == 'l'
    assert: stream.peek_byte!(7) == 'i'
    assert: stream.peek_byte!(8) == 'n'
    assert: stream.peek_byte!(9) == 'g'
    assert: stream.peek_byte!(10) == 's'
    assert error: stream.peek_byte!(11)

    // Rewind then advance the cursor across the first chunk boundary.
    stream.rewind_to_marker
    assert no_error: stream.advance!(3)
    assert: stream.bytes_ahead == 9
    assert: stream.bytes_ahead_of_marker == 12
    assert: stream.token_byte_size == 3
    assert: stream.token_as_string == "low"

    // Rewind then advance the cursor across both chunk boundaries.
    stream.rewind_to_marker
    assert no_error: stream.advance!(10)
    assert: stream.bytes_ahead == 2
    assert: stream.bytes_ahead_of_marker == 12
    assert: stream.token_byte_size == 10
    assert: stream.token_as_string == "loworldlin"

    // Rewind then advance the cursor to the end exactly without error.
    stream.rewind_to_marker
    assert no_error: stream.advance!(12)
    assert: stream.bytes_ahead == 0
    assert: stream.bytes_ahead_of_marker == 12
    assert: stream.token_byte_size == 12
    assert: stream.token_as_string == "loworldlings"

    // Rewind then try to advance the cursor past the end, raising an error.
    stream.rewind_to_marker
    assert error: stream.advance!(13)
    assert: stream.bytes_ahead == 0
    assert: stream.bytes_ahead_of_marker == 12
    assert: stream.token_byte_size == 12
    assert: stream.token_as_string == "loworldlings"

    // Rewind then advance the cursor to the end exactly using advance_to_end.
    stream.rewind_to_marker
    stream.advance_to_end
    assert: stream.bytes_ahead == 0
    assert: stream.bytes_ahead_of_marker == 12
    assert: stream.token_byte_size == 12
    assert: stream.token_as_string == "loworldlings"

    // Rewind and advance across the first chunk boundary using a condition.
    stream.rewind_to_marker
    assert no_error: stream.advance_while! -> (byte | byte != 'r')
    assert: stream.bytes_ahead == 8
    assert: stream.bytes_ahead_of_marker == 12
    assert: stream.token_byte_size == 4
    assert: stream.token_as_string == "lowo"

    // Rewind and advance across both chunk boundaries using a condition.
    stream.rewind_to_marker
    assert no_error: stream.advance_while! -> (byte | byte != 'n')
    assert: stream.bytes_ahead == 3
    assert: stream.bytes_ahead_of_marker == 12
    assert: stream.token_byte_size == 9
    assert: stream.token_as_string == "loworldli"

    // Rewind and advance with a condition that reaches the end (for an error).
    stream.rewind_to_marker
    assert error: stream.advance_while! -> (byte | byte >= 'a')
    assert: stream.bytes_ahead == 0
    assert: stream.bytes_ahead_of_marker == 12
    assert: stream.token_byte_size == 12
    assert: stream.token_as_string == "loworldlings"

    // Clear the state entirely.
    stream.clear
    assert: stream.bytes_ahead == 0
    assert: stream.bytes_ahead_of_marker == 0
    assert: stream.token_byte_size == 0
    assert: stream.token_as_string == ""

  :it "yields each byte of a token"
    stream = ByteStream.ChunkedReader.new
    stream << b"hel"
    stream << b"lowo"
    stream << b"rld"

    collected Array(U8) = []

    // Collect the entire stream.
    stream.advance_to_end
    stream.each_token_byte -> (byte | collected << byte)
    assert: collected == ['h', 'e', 'l', 'l', 'o', 'w', 'o', 'r', 'l', 'd']
    collected.clear

    // Collect a subset of the stream.
    stream.rewind_to_marker
    assert no_error: stream.advance!(2)
    stream.mark_here
    assert no_error: stream.advance!(6)
    stream.each_token_byte -> (byte | collected << byte)
    assert: collected == ['l', 'l', 'o', 'w', 'o', 'r']
    collected.clear

  :it "yields each byte of a token until the block returns True"
    stream = ByteStream.ChunkedReader.new
    stream << b"hel"
    stream << b"lowo"
    stream << b"rld"

    collected Array(U8) = []

    // Collect part of the stream, as dictated by the condition.
    stream.advance_to_end
    stream.each_token_byte_until -> (byte |
      if (byte == 'w') (
        True // stop iteration
      |
        collected << byte
        False // continue iteration
      )
    )
    assert: collected == ['h', 'e', 'l', 'l', 'o']
    collected.clear

  :it "compares a token for equivalence to a given string"
    stream = ByteStream.ChunkedReader.new
    stream << b"hel"
    stream << b"lowo"
    stream << b"rld"

    // Compare the entire stream.
    stream.advance_to_end
    assert: stream.is_token_equal_to("helloworld")
    assert: stream.is_token_equal_to("helloworldz").is_false
    assert: stream.is_token_equal_to("helloworl").is_false
    assert: stream.is_token_equal_to("helloWorld").is_false

    // Compare a subset of the stream.
    stream.rewind_to_marker
    assert no_error: stream.advance!(2)
    stream.mark_here
    assert no_error: stream.advance!(6)
    assert: stream.is_token_equal_to("llowor")
    assert: stream.is_token_equal_to("lloworl").is_false
    assert: stream.is_token_equal_to("llowo").is_false
    assert: stream.is_token_equal_to("lloWor").is_false

  :it "compares an ASCII-lowercased token for equivalence to a given string"
    stream = ByteStream.ChunkedReader.new
    stream << b"HeL"
    stream << b"LoWo"
    stream << b"RlD"

    // Compare the entire stream.
    stream.advance_to_end
    assert: stream.is_token_ascii_lowercase_equal_to("helloworld")
    assert: stream.is_token_ascii_lowercase_equal_to("helloworldz").is_false
    assert: stream.is_token_ascii_lowercase_equal_to("helloworl").is_false
    assert: stream.is_token_ascii_lowercase_equal_to("helloWorld").is_false

    // Compare a subset of the stream.
    stream.rewind_to_marker
    assert no_error: stream.advance!(2)
    stream.mark_here
    assert no_error: stream.advance!(6)
    assert: stream.is_token_ascii_lowercase_equal_to("llowor")
    assert: stream.is_token_ascii_lowercase_equal_to("lloworl").is_false
    assert: stream.is_token_ascii_lowercase_equal_to("llowo").is_false
    assert: stream.is_token_ascii_lowercase_equal_to("lloWor").is_false

  :it "parses a token as a positive integer in decimal notation"
    stream = ByteStream.ChunkedReader.new
    stream << b"192"
    stream << b"8374"
    stream << b"650"

    // Parse the entire stream as an integer.
    stream.advance_to_end
    assert: stream.token_as_positive_integer! == 1928374650

    // Parse a subset of the stream as an integer.
    stream.rewind_to_marker
    assert no_error: stream.advance!(2)
    stream.mark_here
    assert no_error: stream.advance!(6)
    assert: stream.token_as_positive_integer! == 283746

    // Add an invalid character to the stream and get an error.
    stream << b":" // only digits (0-9) are valid
    stream.advance_to_end
    assert error: stream.token_as_positive_integer!

  :it "reads byte at position"
    stream = ByteStream.ChunkedReader.new
    stream << Bytes.from_array([0x01])
    stream << Bytes.from_array([0x23, 0x45])
    stream.advance_to_end

    assert: stream.read_byte!(0) == 0x01
    assert: stream.read_byte!(1) == 0x23
    assert: stream.read_byte!(2) == 0x45
    assert error: stream.read_byte!(3)

  :it "reads integers in native, big and little endianness at specific offsets"
    stream = ByteStream.ChunkedReader.new
    // break the data up into multiple chunks to test reading integers across chunk boundaries
    stream << b"garbage"
    stream << Bytes.from_array([0x01])
    stream << Bytes.from_array([0x23, 0x45])
    stream << Bytes.from_array([0x67, 0x89, 0xAB])
    stream << Bytes.from_array([0xCD])
    stream << Bytes.from_array([0xEF, 0x01])

    try stream.advance!(7) // drop "garbage"
    stream.mark_here
    stream.advance_to_end

    assert: stream.read_native_u16!(0) == 0x2301
    assert: stream.read_native_u16!(1) == 0x4523
    assert: stream.read_native_u32!(0) == 0x67452301
    assert: stream.read_native_u32!(1) == 0x89674523
    assert: stream.read_native_u64!(0) == 0xEFCDAB8967452301
    assert: stream.read_native_u64!(1) == 0x01EFCDAB89674523

    assert: stream.read_le_u16!(0) == 0x2301
    assert: stream.read_le_u16!(1) == 0x4523
    assert: stream.read_le_u32!(0) == 0x67452301
    assert: stream.read_le_u32!(1) == 0x89674523
    assert: stream.read_le_u64!(0) == 0xEFCDAB8967452301
    assert: stream.read_le_u64!(1) == 0x01EFCDAB89674523

    assert: stream.read_be_u16!(0) == 0x0123
    assert: stream.read_be_u16!(1) == 0x2345
    assert: stream.read_be_u32!(0) == 0x01234567
    assert: stream.read_be_u32!(1) == 0x23456789
    assert: stream.read_be_u64!(0) == 0x0123456789ABCDEF
    assert: stream.read_be_u64!(1) == 0x23456789ABCDEF01

