:class _TreeBuilder
  :is PEG.Parser.Builder(
    _Token
    CapnProto.Message.Builder(SaviProto.AST.Document.Builder)
  )
  :var code: "" // TODO: remove this field and add it as an arg to build fn?
  :var error: _Error.List.new

  :fun ref build(tokens Array(PEG.Token(_Token))'val)
    message =
      CapnProto.Message.Builder(SaviProto.AST.Document.Builder).new(0x4000)
    @_build_all(message.root, _TreeBuilder.Data.new(@code, tokens))
    message

  :fun ref _build_all(
    doc SaviProto.AST.Document.Builder
    data _TreeBuilder.Data
  )
    // Get the first token.
    // If there aren't any tokens in the stream, return early.
    index = 0
    token = try (data[index]! | return)

    // Confirm the initial token type.
    if token.kind != _Token.Document (
      @error.at(token, _Error.BugInitialTokenIsNotDocument)
      return
    )

    // Build the top-level document.
    @_build_doc(doc, data, token, index)

  :fun ref _build_pos(
    pos SaviProto.Source.Pos.Builder
    token PEG.Token(_Token)
  )
    None // TODO: Fill in the source position information.

  :fun ref _build_doc(
    doc SaviProto.AST.Document.Builder
    data _TreeBuilder.Data
    token PEG.Token(_Token)
    index USize
  )
    pending_annotations Array(PEG.Token(_Token)) = []

    // Allocate enough space for as many declares as it has token children.
    // (Not all of them will actually become declares, though, as some of
    // them may be body terms to be put inside of declare bodies).
    children_count = data.count_children_of(index)
    declares = doc.init_declares(children_count)

    // Get the first declare.
    // If there aren't any declares in the document, return early.
    declare = try (declares[0]! | return)
    body_terms = declare.body.init_terms(children_count)

    // Collect the declares and declare body terms into a list of declares.
    declare_count USize = 0
    body_term_count USize = 0
    data.each_child_with_index_of(index) -> (child_token, child_index |
      case child_token.kind == (
      | _Token.Annotation |
        pending_annotations << child_token

      | _Token.Declare |
        // Trim the body terms list to the count and reset the count.
        // That's all the body terms we have for the prior declare,
        // and any future body terms will go into this new declare.
        declare.body.trim_terms(0, body_term_count)
        body_term_count = 0

        // Create the new declare, grab the terms list to put terms into,
        // and update the count of how many declares we've seen so far.
        declare = try (declares[declare_count]! |
          @error.at(child_token, _Error.BugFixedSizeListIsTooSmall)
          return
        )
        body_terms = declare.body.init_terms(children_count)
        declare_count += 1

        // Add any pending annotations to the declare node.
        if pending_annotations.is_not_empty (
          docs = declare.init_docs(pending_annotations.size)
          pending_annotations.each_with_index -> (annotation_token, annotation_index |
            try @_build_annotation(docs[annotation_index]!, data, annotation_token)
          )
          pending_annotations.clear
        )

        @_build_declare(declare, data, child_token, child_index)
      |
        declare.body.style = SaviProto.AST.Group.Style.Root

        // Allocate space for as many body terms as it has token children.
        // (Not all of them will actually become body terms, though, as some of
        // them may be other declares, or body terms of those other declares).
        body_term = try (body_terms[body_term_count]! |
          @error.at(child_token, _Error.BugFixedSizeListIsTooSmall)
          return
        )
        body_term_count += 1

        // TODO: Add any pending annotations to the term node.
        if pending_annotations.is_not_empty (
          pending_annotations.each -> (annotation_token |
            @error.at(annotation_token, _Error.ToDoAnnotations)
          )
        )

        @_build_ast(body_term, data, child_token, child_index)
      )
    )

    // TODO: Set body pos for each declare with a body.

    // Trim the final declare, and also the list of declares, to the right size.
    // This is the last step; we won't see any other content in the document.
    declare.body.trim_terms(0, body_term_count)
    doc.trim_declares(0, declare_count)

    @

  :fun ref _build_declare(
    declare SaviProto.AST.Declare.Builder
    data _TreeBuilder.Data
    token PEG.Token(_Token)
    index USize
  )
    // @_build_pos(declare.pos, token)
    @_build_ast_list(
      declare.init_terms(data.count_children_of(index))
      data, token, index
    )

  :fun ref _build_annotation(
    annotation SaviProto.AST.Annotation.Builder
    data _TreeBuilder.Data
    token PEG.Token(_Token)
  )
    // @_build_pos(annotation.pos, token)
    annotation.value = data.get_string(token)

  :fun ref _build_operator(
    op SaviProto.AST.Operator.Builder
    data _TreeBuilder.Data
    token PEG.Token(_Token)
    index USize
  )
    // @_build_pos(op.pos, token)
    op.value = data.get_string(token)

  :fun ref _build_group(
    group SaviProto.AST.Group.Builder
    data _TreeBuilder.Data
    token PEG.Token(_Token)
    index USize
  )
    // @_build_pos(group.pos, token)

    first_byte = data.get_first_byte(token)
    last_byte = data.get_last_byte(token)
    group.has_exclamation = last_byte == '!'
    group.style = if token.kind == _Token.GroupWhitespace (
      SaviProto.AST.Group.Style.Space
    |
      case first_byte == (
      | '(' | SaviProto.AST.Group.Style.Paren
      | '[' | SaviProto.AST.Group.Style.Square
      | '{' | SaviProto.AST.Group.Style.Curly
      | @error.at(token, _Error.BugInvalidGroupStyleByte), return
      )
    )

    // TODO: Handle `|` operator token to create a pipe-partitioned group.

    @_build_ast_list(
      group.init_terms(data.count_children_of(index))
      data, token, index
    )

  :fun ref _build_ast_list(
    list CapnProto.List.Builder(SaviProto.AST.Builder)
    data _TreeBuilder.Data
    token PEG.Token(_Token)
    index USize
  )
    term_count USize = 0
    data.each_child_with_index_of(index) -> (child_token, child_index |
      try (
        @_build_ast(list[term_count]!, data, child_token, child_index)
      |
        @error.at(token, _Error.BugFixedSizeListIsTooSmall)
      )
      term_count += 1
    )

  :fun ref _build_ast(
    ast SaviProto.AST.Builder
    data _TreeBuilder.Data
    token PEG.Token(_Token)
    index USize
  )
    // @_build_pos(ast.pos, token)
    children_count = data.count_children_of(index)

    // Parsing operator precedeence without too much nested backtracking
    // requires us to generate a lot of false positive relates in the grammar
    // (child-carrying tokens that end up with only one child).
    // When that happens, the outer token disappears and we keep only the child.
    if (children_count == 1 && (
      token.kind == _Token.Relate ||
      token.kind == _Token.RelateAssign ||
      token.kind == _Token.Compound
    )) (
      data.each_child_with_index_of(index) -> (child_token, child_index |
        @_build_ast(ast, data, child_token, child_index)
      )
      return
    )

    case token.kind == (
    | _Token.Annotation |
      @error.at(token, _Error.ToDoAnnotations)

    | _Token.Identifier |
      ast.init_name(data.get_string(token))

    | _Token.String |
      if children_count == 0 (
        try (
          ast.init_string(
            _StringLiterals.process_escapes!(data.get_string(token))
          )
        |
          @error.at(token, _Error.StringInvalid)
        )
      |
        @error.at(token, _Error.ToDoComposeString)
      )

    | _Token.BracketString |
      if children_count == 0 (
        ast.init_string(
          _StringLiterals.process_bracket_string_indentation(
            data.get_string(token)
          )
        )
      |
        @error.at(token, _Error.ToDoComposeString)
      )

    | _Token.PrefixedString |
      try (
        error! if children_count != 2

        string_with_prefix = ast.init_string_with_prefix

        child_info = try (data.nth_child_with_index_of!(index, 0) | return)
        child_token = child_info.head, child_index = child_info.tail
        string_with_prefix.string =
          _StringLiterals.process_escapes!(data.get_string(child_token))

        child_info = try (data.nth_child_with_index_of!(index, 1) | return)
        child_token = child_info.head, child_index = child_info.tail
        @_build_operator(string_with_prefix.prefix, data, child_token, child_index)
      |
        @error.at(token, _Error.ToDoComposeString)
      )

    | _Token.BinaryInteger |
      try (
        ast.init_positive_integer(data.get_parsed_binary_u64!(token))
      |
        @error.at(token, _Error.IntegerTooBig)
      )

    | _Token.HexadecimalInteger |
      try (
        ast.init_positive_integer(data.get_parsed_hexadecimal_u64!(token))
      |
        @error.at(token, _Error.IntegerTooBig)
      )

    | _Token.DecimalInteger |
      try (
        pair = data.get_parsed_decimal_u64!(token)
        is_positive = pair.first, u64_value = pair.second
        if is_positive (
          ast.init_positive_integer(u64_value)
        |
          ast.init_negative_integer(u64_value)
        )
      |
        @error.at(token, _Error.IntegerTooBig)
      )

    | _Token.Character |
      try (
        _StringLiterals.process_escapes!(
          data.get_string(token)
        ).each_char_with_index_and_width -> (char, index, width |
          // We rely on the parser to have ensured there is exactly one character.
          ast.init_character(char.u64)
        )
      |
        @error.at(token, _Error.CharacterInvalid)
      )

    | _Token.FloatingPoint |
      try (
        ast.init_floating_point(data.get_parsed_f64!(token))
      |
        @error.at(token, _Error.FloatingPointInvalid)
      )

    | _Token.Group |
      @_build_group(ast.init_group, data, token, index)

    | _Token.GroupWhitespace |
      @_build_group(ast.init_group, data, token, index)

    | _Token.Prefix |
      prefix = ast.init_prefix

      child_info = try (data.nth_child_with_index_of!(index, 0) | return)
      child_token = child_info.head, child_index = child_info.tail
      @_build_operator(prefix.op, data, child_token, child_index)

      child_info = try (data.nth_child_with_index_of!(index, 1) | return)
      child_token = child_info.head, child_index = child_info.tail
      @_build_ast(prefix.term, data, child_token, child_index)

    | _Token.RelateAssign |
      child_number USize = 0
      while child_number < children_count (
        child_info = try (data.nth_child_with_index_of!(index, child_number) | next)
        child_token = child_info.head, child_index = child_info.tail

        remaining_children_count = children_count - child_number
        case (
        | child_token.kind == _Token.Annotation |
          @error.at(child_token, _Error.ToDoAnnotations)
          return

        | remaining_children_count > 2 |
          relate = ast.init_relate
          @_build_ast(relate.terms.left, data, child_token, child_index)

          child_number += 1
          child_info = try (data.nth_child_with_index_of!(index, child_number) | next)
          child_token = child_info.head, child_index = child_info.tail
          if child_token.kind != _Token.Operator (
            @error.at(child_token, _Error.BugUnexpectedGrammarToken)
            next
          )
          @_build_operator(relate.op, data, child_token, child_index)

          ast = relate.terms.right

        | remaining_children_count == 1 |
          @_build_ast(ast, data, child_token, child_index)

        |
          @error.at(child_token, _Error.BugUnexpectedGrammarToken)
        )

        child_number += 1
      )

    | _Token.Relate |
      child_number = children_count
      while child_number > 0 (
        child_number -= 1
        child_info = try (data.nth_child_with_index_of!(index, child_number) | next)
        child_token = child_info.head, child_index = child_info.tail

        case (
        | child_token.kind == _Token.Annotation |
          @error.at(child_token, _Error.ToDoAnnotations)
          return

        | child_number > 1 |
          relate = ast.init_relate
          @_build_ast(relate.terms.right, data, child_token, child_index)

          child_number -= 1
          child_info = try (data.nth_child_with_index_of!(index, child_number) | next)
          child_token = child_info.head, child_index = child_info.tail
          if child_token.kind != _Token.Operator (
            @error.at(child_token, _Error.BugUnexpectedGrammarToken)
            next
          )
          @_build_operator(relate.op, data, child_token, child_index)

          ast = relate.terms.left

        | child_number == 0 |
          @_build_ast(ast, data, child_token, child_index)

        |
          @error.at(child_token, _Error.BugUnexpectedGrammarToken)
        )
      )

    | _Token.Compound |
      child_number = children_count
      while child_number > 0 (
        child_number -= 1
        child_info = try (data.nth_child_with_index_of!(index, child_number) | next)
        child_token = child_info.head, child_index = child_info.tail

        case (
        | child_token.kind == _Token.Annotation |
          @error.at(child_token, _Error.ToDoAnnotations)
          return

        | child_token.kind == _Token.Group && child_number > 0 |
          qualify = ast.init_qualify
          @_build_group(qualify.group, data, child_token, child_index)

          ast = qualify.term

        | child_number > 1 |
          relate = ast.init_relate
          @_build_ast(relate.terms.right, data, child_token, child_index)

          child_number -= 1
          child_info = try (data.nth_child_with_index_of!(index, child_number) | next)
          child_token = child_info.head, child_index = child_info.tail
          if child_token.kind != _Token.Operator (
            @error.at(child_token, _Error.BugUnexpectedGrammarToken)
            next
          )
          @_build_operator(relate.op, data, child_token, child_index)

          ast = relate.terms.left

        | child_number == 0 |
          @_build_ast(ast, data, child_token, child_index)

        |
          @error.at(child_token, _Error.BugUnexpectedGrammarToken)
        )
      )
    |
      @error.at(token, _Error.ToDoAnnotations)
    )

    @
