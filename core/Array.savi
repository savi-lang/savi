:class ref Array(A)
  :copies Indexable(A) // TODO: should be `:is` instead of `:copies`

  :var _size USize
  :var _space USize
  :var _ptr CPointer(A)'ref
  :new ref from_cpointer(@_ptr, @_size, @_space)
  :new iso iso_from_cpointer(@_ptr, @_size, @_space) // TODO: remove this and use recover instead?
  :new val val_from_cpointer(@_ptr, @_size, @_space) // TODO: remove this and use recover instead?

  :fun ref _ptr_set_null
    @_space = 0
    @_ptr = CPointer(A)._null

  :fun ref _ptr_allocate(space USize)
    @_space = space.next_pow2.clamp_min(space).clamp_min(8)
    @_ptr = CPointer(A)._alloc(@_space)

  :fun ref _ptr_reallocate(space USize)
    @_space = space.next_pow2.clamp_min(space).clamp_min(8)
    @_ptr = @_ptr._realloc(@_space)

  :new (space USize = 0)
    @_size = 0
    if (space > 0) (@_ptr_allocate(space) | @_ptr_set_null)

  :new iso new_iso(space USize = 0) // TODO: use recover instead of this hack
    @_size = 0
    if (space > 0) (@_ptr_allocate(space) | @_ptr_set_null)

  :fun size: @_size
  :fun space: @_space
  :fun cpointer(offset = 0) CPointer(A)'tag: @_ptr._offset(offset) // TODO: simply tag as return type; infer CPointer(A) part of it

  :fun is_empty: @_size == 0
  :fun is_not_empty: @_size != 0
  :fun ref clear: @_size = 0, @

  :fun ref truncate(size): @_size = @_size.clamp_max(size)

  :fun val trim(from USize, to USize = -1)
    to = to.clamp_max(@_size)
    from = from.clamp_max(to)
    size = to - from

    space = if (to == @_size) (
      // If our new final address lines up with the current final address,
      // then we can keep any extra bytes allocated beyond the current size.
      // We'll only trim off the left side.
      @_space - from
    |
      // Otherwise, we can't keep the extra allocated bytes, and therefore
      // the new allocation size is the same as the new occupied size
      size
    )

    ptr = if (space == 0) (
      // If the new allocation space is zero, use a null pointer to avoid issue.
      CPointer(A)._null
    |
      // Otherwise, use a pointer offset from the original one to trim the left.
      @_ptr._offset(from)
    )

    @val_from_cpointer(ptr, size, space)

  :fun ref trim_in_place(from USize, to USize = -1)
    to = to.clamp_max(@_size)
    from = from.clamp_max(to)
    size = to - from

    if (to == @_size) (
      // If our new final address lines up with the current final address,
      // then we can keep any extra bytes allocated beyond the current size.
      // We'll only trim off the left side.
      @_space -= from
    |
      // Otherwise, we can't keep the extra allocated bytes, and therefore
      // the new allocation size is the same as the new occupied size
      @_space = size
    )

    @_size = size

    if (@_space == 0) (
      // If the new allocation space is zero, use a null pointer to avoid issue.
      @_ptr = CPointer(A)._null
    |
      // Otherwise, use a pointer offset from the original one to trim the left.
      @_ptr = @_ptr._offset(from)
    )

    @

  :: Reserve enough total space for the given number of elements.
  :: The size (number of actual elements present in the array) does not change.

  :fun ref reserve(space USize)
    if (@_space < space) \
      @_ptr_reallocate(space)
    @

  :: Create a clone of this array, containing references to the same elements
  :: that are held by this array. This is only safe if the references are
  :: aliasable as themselves (with non-unique reference capabilities), so
  :: if the element type isn't aliasable, the cloned array will be empty.

  :fun clone @'iso
    if (A <: alias) (
      array = @new_iso(@size)
      _ptr_tag CPointer(A)'tag = @_ptr // TODO: this indirection shouldn't be needed
      array._clone_from(_ptr_tag, @size)
      array._size = @size
      --array
    |
      @new_iso(0)
    )

  :fun ref _clone_from(other_ptr CPointer(A), size USize)
    other_ptr._unsafe._copy_to(@_ptr, size)

  :fun "[]!"(index) @->(A'aliased)
    if (@size <= index) error!
    @_ptr._get_at(index)

  :fun ref "[]=!"(index, value)
    if (@size <= index) error!
    @_ptr._assign_at(index, --value)

  :fun ref "[]<<=!"(index, value)
    if (@size <= index) error!
    @_ptr._displace_at(index, --value)

  :fun ref "<<"(value): @push(--value)
  :fun ref push(value)
    @reserve(@_size + 1)
    @_ptr._assign_at(@_size, --value)
    @_size = @_size + 1
    @

  :fun ref pop! A
    @_size = @_size -! 1
    @_ptr._get_at_no_alias(@_size)

  :: Return the first element in the array.
  :: Raises an error if the array is empty.
  :fun first! @->(A'aliased)
    error! if (@size == 0)
    @_ptr._get_at(0)

  :: Assign the given value to replace the first element in the array.
  :: Raises an error if the array is empty.
  :fun ref "first=!"(value A)
    error! if (@size == 0)
    @_ptr._assign_at(0, --value)

  :: Return the last element in the array.
  :: Raises an error if the array is empty.
  :fun last! @->(A'aliased)
    @_ptr._get_at(@size -! 1)

  :: Assign the given value to replace the last element in the array.
  :: Raises an error if the array is empty.
  :fun ref "last=!"(value A)
    @_ptr._assign_at(@size -! 1, --value)

  :fun "!="(other): (@ == other).is_false // TODO: move this to the Equatable trait?
  :fun "=="(other Array(A)'box)
    // TODO: optimize for cases when the elements can be pointer-compared by
    // value/identity instead of structural equality (e.g. Array(U8))
    equal_so_far = (@size == other.size)
    index USize = 0
    while (equal_so_far && index < @_size) (
      equal_so_far = if (A <: Equatable(A)'read) (
        @_ptr._get_at(index) == other._ptr._get_at(index)
      |
        @_ptr._get_at(index) === other._ptr._get_at(index)
      )
      index = index + 1
    )
    equal_so_far

  :fun ref replace_at!(index)
    :yields A for A
    error! if (@size <= index)

    new_value = yield @_ptr._get_at_no_alias(index)
    new_value_alias = new_value
    @_ptr._assign_at(index, --new_value)

    new_value_alias

  :fun each_with_index(
    from USize = 0
    to = USize.max_value
    stride USize = 1
  )
    to = @_size.clamp_max(to)
    index = from
    while (index < to) (
      yield (@_ptr._get_at(index), index)
      index += stride
    )
    None

  :fun reverse_each_with_index(
    from = USize.max_value
    to USize = 0
    stride USize = 1
  )
    try (
      index USize = @_size.clamp_max(from) -! 1
      while (index >= to) (
        yield (@_ptr._get_at(index), index)
        index = index -! stride
      )
    )
    None

  :fun includes(expected A)
    // TODO: Move to Indexable trait and implement in terms of `each` or `find!`
    // This currently doesn't work due to a bug in type refinement logic.
    // @each -> (value |
    //   if (A <: Equatable(A)'read) (
    //     return True if value == expected
    //   |
    //     return True if value === expected
    //   )
    // )
    // False
    is_found = False
    index USize = 0
    while (!is_found && index < @_size) (
      is_found = if (A <: Equatable(A)'read) (
        @_ptr._get_at(index) == expected
      |
        @_ptr._get_at(index) === expected
      )
      index += 1
    )
    is_found

  :: Return a copy of the array that has its elements sorted by value.
  :: If the element type is not aliasable, or not Comparable, it will be empty.

  :fun sort: @clone.sort_in_place

  :: Mutate the array to sort its elements by value.
  :: If the element type is not Comparable, there is no way to sort the values,
  :: so the array will be emptied of all elements, in order to make the
  :: issue as obvious as possible while not penalizing proper usage.

  :fun ref sort_in_place
    if @_sort_in_place(0, @size.isize - 1) (@ | @clear)

  :fun ref _sort_in_place(lo_pivot ISize, hi_pivot ISize) Bool // TODO: should be actually private
    if (A <: Comparable(A)'read) (
      if (lo_pivot < hi_pivot) (
        // Choose the outermost elements as pivots, ensuring that the higher
        // of the two is on the right, swapping to make it so if needed.
        lo_pivot_value = @_ptr._get_at(lo_pivot.usize)
        hi_pivot_value = @_ptr._get_at(hi_pivot.usize)
        if (lo_pivot_value > hi_pivot_value) (
          @_ptr._assign_at(lo_pivot.usize, hi_pivot_value)
          @_ptr._assign_at(hi_pivot.usize, lo_pivot_value)
          lo_pivot_value = @_ptr._get_at(lo_pivot.usize)
          hi_pivot_value = @_ptr._get_at(hi_pivot.usize)
        )

        // Create our three moving cursors inside the pivot range:
        // `lo` moves upward starting from the bottom of the range
        // `hi` moves downward starting from the top of the range
        // `scan` moves upward between the two
        lo = lo_pivot + 1, hi = hi_pivot - 1
        scan = lo

        // Scan the range, swapping as necessary.
        while (scan <= hi) (scan_value = @_ptr._get_at(scan.usize)
          case (
          // When we scan a value less than our pivot, swap the value downward.
          | scan_value < lo_pivot_value |
            @_ptr_swap(scan.usize, lo.usize) // TODO: these swap operations can be optimized by leveraging earlier pointer reads, though it will be more verbose
            lo += 1

          // When we scan a value greater than our pivot, swap the value upward.
          | scan_value >= hi_pivot_value |
            // First move `hi` cursor until it's greater than the `hi_pivot`.
            while (@_ptr._get_at(hi.usize) > hi_pivot_value && scan < hi) (
              hi -= 1
            )

            // Swap the scanned value upward.
            @_ptr_swap(scan.usize, hi.usize) // TODO: these swap operations can be optimized by leveraging earlier pointer reads, though it will be more verbose
            hi -= 1

            // Possibly swap the just-swapped value downward if it needs to be.
            // Note that `scan_value` here is the previous `hi` value.
            scan_value = @_ptr._get_at(scan.usize)
            if (scan_value < lo_pivot_value) (
              @_ptr_swap(scan.usize, lo.usize) // TODO: these swap operations can be optimized by leveraging earlier pointer reads, though it will be more verbose
              lo += 1
            )
          )
          scan += 1
        )

        // Re-expand to the true range now that we've finished scanning.
        lo -= 1
        hi += 1

        // Swap the pivots to their final positions.
        @_ptr_swap(lo_pivot.usize, lo.usize) // TODO: these swap operations can be optimized by leveraging earlier pointer reads, though it will be more verbose
        @_ptr_swap(hi_pivot.usize, hi.usize) // TODO: these swap operations can be optimized by leveraging earlier pointer reads, though it will be more verbose

        // Recursively sort the three sub-ranges left inside this range.
        @_sort_in_place(lo_pivot, lo - 1)
        @_sort_in_place(lo + 1, hi - 1)
        @_sort_in_place(hi + 1, hi_pivot)
      )
      True
    |
      False // return false if the elements are not Comparable
    )

  :fun ref swap!(index_1, index_2)
    error! if (@size <= index_1)
    error! if (@size <= index_2)
    @_ptr_swap(index_1, index_2)

  :fun ref _ptr_swap(index_1 USize, index_2 USize)
    value_1 = @_ptr._get_at_no_alias(index_1)
    value_2 = @_ptr._get_at_no_alias(index_2)
    @_ptr._assign_at(index_1, --value_2)
    @_ptr._assign_at(index_2, --value_1)
    None
